{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "###############################################################################################################################################\n",
    "# Data Preparation\n",
    "# ================\n",
    "import sagemaker\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "# Initialize SageMaker session and specify bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "# Load Iris dataset\n",
    "iris_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "header=None)\n",
    "iris_data.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "# Convert species to numeric values\n",
    "iris_data['species'] = iris_data['species'].astype('category').cat.codes\n",
    "print(iris_data['species'].unique()) # Should output [0, 1, 2]\n",
    "# Split data into train and validation sets\n",
    "train_data, val_data = train_test_split(iris_data, test_size=0.2, random_state=42)\n",
    "# Move the label column to the front of the dataframe\n",
    "train_data = train_data[['species', 'sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "val_data = val_data[['species', 'sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "# Save locally as CSV\n",
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "val_data.to_csv('validation.csv', header=False, index=False)\n",
    "# one can print the train_data and the val_data that would be the 80% training data 20% validation data\n",
    "###############################################################################################################################################\n",
    "\n",
    "# upload the tain_data and val_data to S3 bucket\n",
    "s3_train_path = sagemaker_session.upload_data(path='train.csv', bucket=bucket, key_prefix='xgboost-iris/train')\n",
    "s3_validation_path = sagemaker_session.upload_data(path='validation.csv', bucket=bucket, key_prefix='xgboost-iris/validation')\n",
    "print(f\"Training data uploaded to: {s3_train_path}\")\n",
    "print(f\"Validation data uploaded to: {s3_validation_path}\")\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "# Specify the XGBoost container\n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"1.5-1\")\n",
    "# Set XGBoost hyperparameters\n",
    "xgboost = sagemaker.estimator.Estimator(\n",
    "container,\n",
    "role,\n",
    "instance_count=1,\n",
    "instance_type='ml.m5.large',\n",
    "output_path=f's3://{bucket}/xgboost-iris/output', sagemaker_session=sagemaker_session)\n",
    "xgboost.set_hyperparameters(\n",
    "objective=\"multi:softmax\",\n",
    "num_class=3, # There are 3 classes in the Iris dataset\n",
    "num_round=100\n",
    ")\n",
    "# Specify input data\n",
    "train_input = sagemaker.inputs.TrainingInput(s3_data=s3_train_path, content_type='csv')\n",
    "validation_input = sagemaker.inputs.TrainingInput(s3_data=s3_validation_path, content_type='csv')\n",
    "# Start the training job\n",
    "xgboost.fit({\"train\": train_input, \"validation\": validation_input})\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "\n",
    "# Deploy the XGBoost model to an endpoint\n",
    "xgboost_predictor = xgboost.deploy(initial_instance_count=1, instance_type='ml.m5.large')\n",
    "# Prepare a sample input for prediction\n",
    "test_data = val_data.drop(columns=['species']).iloc[2].values # Assuming 'species' is the label column\n",
    "test_data = ','.join(map(str, test_data)) # Convert features to a CSV row format\n",
    "print(f\"Test data for prediction: {test_data}\")\n",
    "# Make a prediction\n",
    "response = xgboost_predictor.predict(\n",
    "test_data,\n",
    "initial_args={'ContentType': 'text/csv'} # Specify content type as text/csv\n",
    ")\n",
    "# The response might need decoding, depending on format\n",
    "predicted_class = response.decode('utf-8') # Decode the response to a readable format (if required)\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "# Clean up by deleting the endpoint\n",
    "xgboost_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
